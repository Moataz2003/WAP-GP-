{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c9a59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionXLPipeline, KDPM2AncestralDiscreteScheduler, AutoencoderKL\n",
    "import torch\n",
    "\n",
    "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    vae=vae,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "pipe.scheduler = KDPM2AncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0e36ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "##############################################################################\n",
    "# Load translation model\n",
    "model_name = \"Helsinki-NLP/opus-mt-ar-en\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# Arabic detection regex\n",
    "arabic_char_pattern = re.compile(r'[\\u0600-\\u06FF]')\n",
    "\n",
    "def is_arabic(text):\n",
    "    return len(arabic_char_pattern.findall(text)) > 3\n",
    "\n",
    "def translate_arabic_to_english_preserve_english(text):\n",
    "    if not is_arabic(text):\n",
    "        return text\n",
    "\n",
    "    english_words = re.findall(r'[a-zA-Z0-9@#_.+-]+', text)\n",
    "    placeholder_map = {}\n",
    "    for i, word in enumerate(english_words):\n",
    "        placeholder = f\"ENG{i}\"\n",
    "        text = text.replace(word, placeholder)\n",
    "        placeholder_map[placeholder] = word\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    translated_tokens = model.generate(**inputs)\n",
    "    translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "    for placeholder, word in placeholder_map.items():\n",
    "        translated_text = translated_text.replace(placeholder, word)\n",
    "\n",
    "    return translated_text\n",
    "##############################################################################\n",
    "# Load NLP & Sentiment Models\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "sentiment_tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "sentiment_model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "# Load color dataset\n",
    "color_dataset_path = \"/kaggle/input/ccoolloorrss/colornames_modified.json\"\n",
    "try:\n",
    "    with open(color_dataset_path, \"r\") as f:\n",
    "        color_data = json.load(f)\n",
    "        color_names = {entry[\"name\"].lower() for entry in color_data}\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {color_dataset_path} not found. Using default color set.\")\n",
    "    color_names = set()\n",
    "\n",
    "# --- Shared Sentiment Analysis ---\n",
    "def analyze_sentiment(text):\n",
    "    inputs = sentiment_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = sentiment_model(**inputs)\n",
    "    sentiment_scores = torch.softmax(outputs.logits, dim=1).numpy().flatten()\n",
    "    sentiment_labels = [\"negative\", \"neutral\", \"positive\"]\n",
    "    sentiment_index = np.argmax(sentiment_scores)\n",
    "    base_mood = sentiment_labels[sentiment_index]\n",
    "\n",
    "    mood_mapping = {\n",
    "        \"negative\": [\n",
    "            \"subtle and understated\", \"muted and elegant\", \"dark and dramatic\",\n",
    "            \"reserved and serious\", \"moody and introspective\", \"mysterious and sophisticated\"\n",
    "        ],\n",
    "        \"neutral\": [\n",
    "            \"balanced and harmonious\", \"sophisticated and refined\", \"modern and professional\",\n",
    "            \"minimalist and clean\", \"sleek and polished\", \"contemporary and timeless\"\n",
    "        ],\n",
    "        \"positive\": [\n",
    "            \"bold and energetic\", \"vibrant and dynamic\", \"playful and cheerful\",\n",
    "            \"expressive and artistic\", \"friendly and inviting\", \"joyful and captivating\"\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    confidence_threshold = 0.6\n",
    "    if sentiment_scores[sentiment_index] > confidence_threshold:\n",
    "        selected_mood = np.random.choice(mood_mapping[base_mood])\n",
    "    else:\n",
    "        selected_mood = \"eclectic and expressive\"\n",
    "\n",
    "    if sentiment_scores[0] > 0.3 and sentiment_scores[2] > 0.3:\n",
    "        selected_mood = \"contrasting and experimental\"\n",
    "    elif sentiment_scores[1] > 0.5:\n",
    "        selected_mood = \"timeless and balanced\"\n",
    "\n",
    "    return selected_mood\n",
    "\n",
    "def get_output_style(design_type, mood):\n",
    "    vector_designs = {\n",
    "        \"logo\", \"app icon\", \"business card\", \"branding\", \"character design\", \"product label\", \"slogan\" \n",
    "    }\n",
    "    raster_designs = {\n",
    "        \"poster\", \"album cover\", \"banner\", \"sticker\", \"mockup\", \"advertisement\", \"flyer\", \"billboard\", \"cinema poster\", \"movie poster\", \"campaign poster\"\n",
    "    }\n",
    "    print_designs = {\n",
    "        \"post card\", \"invitation\", \"brochure\", \"menu design\", \"book cover\"\n",
    "    }\n",
    "    digital_ui = {\n",
    "        \"social media post\", \"UI/UX design\", \"e-commerce product image\", \"NFT art\", \"infographic\"\n",
    "    }\n",
    "\n",
    "    # Base logic\n",
    "    if design_type in vector_designs:\n",
    "        return \"vector-based, scalable design\"\n",
    "    elif design_type in raster_designs:\n",
    "        return \"high-resolution raster image\"\n",
    "    elif design_type in print_designs:\n",
    "        return \"print-ready layout (CMYK, 300 DPI)\"\n",
    "    elif design_type in digital_ui:\n",
    "        return \"digital-optimized, responsive layout\"\n",
    "    else:\n",
    "        # Optional fallback based on mood\n",
    "        if \"minimalist\" in mood or \"clean\" in mood:\n",
    "            return \"flat design, minimal elements\"\n",
    "        elif \"artistic\" in mood or \"dynamic\" in mood:\n",
    "            return \"expressive, layered illustration\"\n",
    "        else:\n",
    "            return \"versatile mixed-media style\"\n",
    "\n",
    "# --- Extract Keywords Version 1 (for logos) ---\n",
    "def extract_logo_keywords_v1(user_input):\n",
    "    doc = nlp(user_input)\n",
    "    capitalized_words = [token.text for token in doc if token.text.istitle() or token.text.isupper()]\n",
    "    adjectives = [token.text.lower() for token in doc if token.pos_ == \"ADJ\"]\n",
    "    nouns = [token.text.lower() for token in doc if token.pos_ == \"NOUN\"]\n",
    "    theme = \" \".join(adjectives[:10]) if adjectives else \"unique and creative\"\n",
    "    combined = capitalized_words + nouns\n",
    "    elements = \", \".join(combined[:10]) if combined else \"unique and creative\"\n",
    "\n",
    "    words = re.findall(r\"\\b[a-zA-Z]+\\b\", user_input.lower())\n",
    "    unique_color_words = list({word for word in words if word in color_names})\n",
    "    hex_colors = re.findall(r\"#(?:[0-9a-fA-F]{3}){1,2}\\b\", user_input)\n",
    "    all_colors = unique_color_words + hex_colors\n",
    "\n",
    "    mood = analyze_sentiment(user_input)\n",
    "\n",
    "    requested = next((\n",
    "        label for label in [\n",
    "            \"logo\", \"slogan\", \"poster\", \"post card\", \"advertisement\", \"business card\", \"book cover\", \"sticker\", \"banner\",\n",
    "            \"flyer\", \"brochure\", \"album cover\", \"packaging\", \"social media post\", \"NFT art\", \"app icon\",\n",
    "            \"merchandise\", \"invitation\", \"billboard\", \"infographic\", \"mockup\", \"e-commerce product image\",\n",
    "            \"UI/UX design\", \"menu design\", \"advertising campaign\", \"character design\", \"e-book cover\",\n",
    "            \"business branding\", \"product label\", \"campaign poster\"\n",
    "        ] if label in user_input.lower()\n",
    "    ), \"general design\")\n",
    "\n",
    "    return {\n",
    "        \"requested\": requested,\n",
    "        \"theme\": theme,\n",
    "        \"mood\": mood,\n",
    "        \"elements\": elements,\n",
    "        \"color_scheme\": \", \".join(all_colors) if all_colors else \"default palette\",\n",
    "        \"output_style\": get_output_style(requested_type, mood),\n",
    "    }\n",
    "\n",
    "# --- Extract Keywords Version 2 (for other types) ---\n",
    "def extract_keywords(user_input):\n",
    "    \"\"\"Extracts relevant keywords dynamically using NLP and dependency parsing.\"\"\"\n",
    "    doc = nlp(user_input)\n",
    "\n",
    "    # Define the design types\n",
    "    design_types = {\n",
    "        \"logo\", \"poster\", \"post card\", \"advertisement\", \"business card\", \"movie poster\",\n",
    "        \"book cover\", \"sticker\", \"banner\", \"flyer\", \"brochure\", \"album cover\", \"card\",\n",
    "        \"packaging\", \"social media post\", \"NFT art\", \"app icon\", \"merchandise\", \"character design\",\n",
    "        \"invitation\", \"billboard\", \"infographic\", \"mockup\", \"cinema poster\", \"game poster\",\n",
    "        \"menu design\", \"campaign poster\", \"branding\", \"product label\", \"view\"\n",
    "    }\n",
    "\n",
    "    # Detect requested type\n",
    "    requested_type = next((design for design in design_types if design in user_input.lower()), \"realistic world design\")\n",
    "\n",
    "    # Common: Extract colors\n",
    "    words = re.findall(r\"\\b[a-zA-Z]+\\b\", user_input.lower())\n",
    "    unique_color_words = list({word for word in words if word in color_names})\n",
    "    hex_colors = re.findall(r\"#(?:[0-9a-fA-F]{3}){1,2}\\b\", user_input)\n",
    "    all_colors = unique_color_words + hex_colors\n",
    "\n",
    "    # Common: Sentiment analysis\n",
    "    mood = analyze_sentiment(user_input)\n",
    "\n",
    "    if \"logo\" in requested_type.lower():\n",
    "        # Extract adjectives for themes\n",
    "        adjectives = [token.text.lower() for token in doc if token.pos_ == \"ADJ\"]\n",
    "\n",
    "        # Extract nouns, proper nouns, and verbs for elements\n",
    "        elements = [token.text.lower() for token in doc if token.pos_ in [\"NOUN\", \"PROPN\", \"VERB\"]]\n",
    "\n",
    "        # Extract capitalized words (words that start with a capital letter or are fully capitalized)\n",
    "        capitalized_words = [token.text for token in doc if token.text.istitle() or token.text.isupper()]\n",
    "\n",
    "        # Combine theme and element keywords, prioritizing capitalized words\n",
    "        combined_theme = adjectives + capitalized_words  # Prioritizing capitalized words\n",
    "        theme = \" \".join(combined_theme[:10]) if combined_theme else \"unique and creative\"\n",
    "\n",
    "        # Combine all element keywords, prioritizing capitalized words\n",
    "        combined_elements = capitalized_words + elements\n",
    "        elements = \" \".join(combined_elements[:10]) if combined_elements else \"unique and creative\"\n",
    "\n",
    "\n",
    "    else:\n",
    "        # Second version logic (Non-logo)\n",
    "        adjectives = [token.text.lower() for token in doc if token.pos_ == \"ADJ\" and token.text.lower() not in color_names]\n",
    "        theme = \" \".join(adjectives) if adjectives else \"unique and creative\"\n",
    "\n",
    "        elements = []\n",
    "        for chunk in doc.noun_chunks:\n",
    "            if chunk.root.text.lower() not in stop_words:\n",
    "                elements.append(chunk.text.lower())\n",
    "        elements = list(OrderedDict.fromkeys(elements))\n",
    "        elements = \", \".join(elements) if elements else \"abstract shapes\"\n",
    "\n",
    "    return {\n",
    "        \"requested\": requested_type,\n",
    "        \"theme\": theme,\n",
    "        \"mood\": mood,\n",
    "        \"elements\": elements,\n",
    "        \"color_scheme\": \", \".join(all_colors) if all_colors else \"default palette\",\n",
    "        \"output_style\": get_output_style(requested_type, mood),\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_logo_prompt(brand_name, brand_style, user_input):\n",
    "    \"\"\"Generates a logo or design prompt based on extracted keywords.\"\"\"\n",
    "    keywords = extract_keywords(user_input)\n",
    "\n",
    "    return (\n",
    "        f'{keywords[\"requested\"]} for \"{brand_name}\" with ({brand_style} style). '\n",
    "        f'It should reflect a {keywords[\"theme\"]} theme and evoke a {keywords[\"mood\"]} feeling. '\n",
    "        f'Incorporate {keywords[\"elements\"]} while using a {keywords[\"color_scheme\"]} color palette. '\n",
    "        f'The final design must be {keywords[\"output_style\"]}.'\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Optional Redundancy Cleaner ---\n",
    "def remove_redundancy(prompt):  \n",
    "    words = prompt.split()\n",
    "    unique_words = list(OrderedDict.fromkeys(words))\n",
    "    prompt_cleaned = \" \".join(unique_words)\n",
    "    prompt_cleaned = re.sub(r\"\\b(\\w+ and \\w+)\\b(?=.*\\b\\1\\b)\", r\"\\1\", prompt_cleaned)\n",
    "    return prompt_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a559fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyngrok\n",
    "!pip install flask-cors\n",
    "!ngrok config add-authtoken 2u3LkoKYpHkC0CawsxkYP3KZtp7_6CoGa2Gf6WXPraZg9ABoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d105b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, send_file\n",
    "from flask_cors import CORS\n",
    "from pyngrok import ngrok\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Assumes you have these functions and model pipeline defined somewhere\n",
    "# from your_module import generate_logo_prompt, remove_redundancy, pipe\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "@app.route(\"/generate\", methods=[\"POST\"])\n",
    "def generate():\n",
    "    data = request.get_json()\n",
    "    prmp = data.get(\"prompt\", \"\")\n",
    "    brandName = data.get(\"brandName\", \"\")\n",
    "    brandStyle = data.get(\"brandStyle\", \"\")\n",
    "\n",
    "    raw_prompt = generate_logo_prompt(brandName, brandStyle, translate_arabic_to_english_preserve_english(prmp))\n",
    "    prompt = remove_redundancy(raw_prompt)\n",
    "\n",
    "    print(\"Brand Name:\", brandName)\n",
    "    print(\"-----------------------------------------------------------------------------\")\n",
    "    print(\"Brand Style:\", brandStyle)\n",
    "    print(\"-----------------------------------------------------------------------------\")\n",
    "    print(\"Original:\", prmp)\n",
    "    print(\"-----------------------------------------------------------------------------\")\n",
    "    print(\"Prompt:\", prompt)\n",
    "\n",
    "    image = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=(\n",
    "            \"low quality, blurry, distorted, blurry text, unreadable letters, distorted words, \"\n",
    "            \"low resolution, messy typography, misspelled text, cut-off letters, overlapping text, \"\n",
    "            \"incorrect spacing, warped text, illegible handwriting, pixelated text, fuzzy edges, \"\n",
    "            \"text artifacts, stretched letters, chaotic layout, unclear details, inconsistent font style, \"\n",
    "            \"deformed words, broken letters, random symbols, gibberish text\"\n",
    "        ),\n",
    "        width=1024,\n",
    "        height=1024,\n",
    "        guidance_scale=15,\n",
    "        num_inference_steps=100\n",
    "    ).images[0]\n",
    "\n",
    "    image.save(\"generated.png\")\n",
    "    return send_file(\"generated.png\", mimetype='image/png')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Start ngrok tunnel\n",
    "    public_url = ngrok.connect(5000)\n",
    "    print(\" * ngrok tunnel available at:\", public_url)\n",
    "    print(\" * Running on http://127.0.0.1:5000\")\n",
    "\n",
    "    # Run the Flask app\n",
    "    app.run()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
